

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>From PCA to the Subspace Method &mdash; cvlab_toolbox 0.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/logo.png"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="cvt package" href="../source/cvt.html" />
    <link rel="prev" title="MNIST example with Subspace Method" href="MNIST_example_with_SM.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> cvlab_toolbox
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/installation.html">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/getting_started.html">Subspace Methods at a Glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html">Concepts Walkthrough</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="MNIST_example_with_SM.html">MNIST example with Subspace Method</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">From PCA to the Subspace Method</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#prepare-a-dataset">1. Prepare a dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#peform-pca-on-each-class-and-select-eigenvectors-training">2. Peform PCA on each class and select eigenvectors (Training)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#calculate-cosine-similarities-for-each-subspace-classification">3. Calculate cosine similarities for each subspace (Classification)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bad-use-case-for-sm">4. Bad use case for SM</a></li>
<li class="toctree-l2"><a class="reference internal" href="#good-use-case-for-sm">5. Good use case for SM</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../source/cvt.html">cvt package</a></li>
</ul>
<p class="caption"><span class="caption-text">Contribution</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contribution/contribution.html">Coding styles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribution/contribution.html#contribution-rules">Contribution rules</a></li>
</ul>
<p class="caption"><span class="caption-text">Gallery</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples_scripts/index.html">Gallery</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">cvlab_toolbox</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>From PCA to the Subspace Method</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/examples/pca_to_sm.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="from-pca-to-the-subspace-method">
<h1>From PCA to the Subspace Method<a class="headerlink" href="#from-pca-to-the-subspace-method" title="Permalink to this headline">¶</a></h1>
<p>In the example code of this tutorial, we assume for simplicity that the
following symbols are already imported.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span><span class="p">,</span> <span class="n">make_circles</span><span class="p">,</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">LinearDiscriminantAnalysis</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span><span class="o">,</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">pardir</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">cvt.models</span> <span class="kn">import</span> <span class="n">SubspaceMethod</span>
</pre></div>
</div>
<p>In this example we will start with principal component analysis (PCA)
and work our way to classification with the subspace method (SM).</p>
<p>We will conduct the procedure in the following steps.</p>
<ol class="arabic simple">
<li><p>Prepare a dataset</p></li>
<li><p>Peform PCA on each class and select eigenvectors (Training)</p></li>
<li><p>Calculate cosine similarities for each subspace (Classification)</p></li>
<li><p>Bad use case for SM</p></li>
<li><p>Good use case for SM</p></li>
</ol>
<div class="section" id="prepare-a-dataset">
<h2>1. Prepare a dataset<a class="headerlink" href="#prepare-a-dataset" title="Permalink to this headline">¶</a></h2>
<p>Here we create a random set of data with 2 features.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">make_classification</span></code> function generates data for a random n-class
classification problem.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="c1"># Create a random set of data of 2 dimensions</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Plot the dataset</span>
<span class="n">cm_bright</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">,</span> <span class="s1">&#39;#0000FF&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_4_0.png" src="../_images/output_4_0.png" />
</div>
</div>
<div class="section" id="peform-pca-on-each-class-and-select-eigenvectors-training">
<h2>2. Peform PCA on each class and select eigenvectors (Training)<a class="headerlink" href="#peform-pca-on-each-class-and-select-eigenvectors-training" title="Permalink to this headline">¶</a></h2>
<p>In most cases of the subspace method, PCA is performed on each class to
create subspaces. These subspaces are then used as references to
determine the class of newly introduced data.</p>
<p>In this example, we have only 2 dimensions. Therefore we will choose a 1
dimensional subspace to use for classification.</p>
<p>This 1-dimensional subspace will determined with pca, so it will be the
direction which captures the largest variance.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pca</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tip from https://stackoverflow.com/a/45435548</span>

<span class="sd">    np.eigh guarantees you that the eigenvalues are sorted and</span>
<span class="sd">    uses a faster algorithm that takes advantage of the fact</span>
<span class="sd">    that the matrix is symmetric.</span>
<span class="sd">    If you know that your matrix is symmetric, use this function.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">eig_vals</span><span class="p">,</span> <span class="n">eig_vecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="nd">@X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eig_vals</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">n_components</span><span class="p">],</span> <span class="n">eig_vecs</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">n_components</span><span class="p">]</span>

<span class="n">dct</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">Xc</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="n">c</span><span class="p">)]</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">eig_vecs</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">Xc</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Store subspaces to use later for classification</span>
    <span class="n">dct</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">eig_vecs</span>

    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Eigen vectors from class {c:.0f}:</span><span class="se">\n</span><span class="s1">{eig_vecs}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">Xc</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">eig_vecs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">eig_vecs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
               <span class="n">color</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">angles</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">scale_units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Eigen</span> <span class="n">vectors</span> <span class="kn">from</span> <span class="nn">class</span> <span class="mi">0</span><span class="p">:</span>
<span class="p">[[</span><span class="o">-</span><span class="mf">0.97085135</span> <span class="o">-</span><span class="mf">0.23968241</span><span class="p">]]</span>

<span class="n">Eigen</span> <span class="n">vectors</span> <span class="kn">from</span> <span class="nn">class</span> <span class="mi">1</span><span class="p">:</span>
<span class="p">[[</span><span class="o">-</span><span class="mf">0.69337618</span>  <span class="mf">0.7205758</span> <span class="p">]]</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_6_1.png" src="../_images/output_6_1.png" />
</div>
</div>
<div class="section" id="calculate-cosine-similarities-for-each-subspace-classification">
<h2>3. Calculate cosine similarities for each subspace (Classification)<a class="headerlink" href="#calculate-cosine-similarities-for-each-subspace-classification" title="Permalink to this headline">¶</a></h2>
<p>Next, to classify data we calculate the cosine similarities between the
input vector and each subspace.</p>
<div class="figure align-default" id="id1">
<img alt="image.png" src="examples/attachment:image.png" />
<p class="caption"><span class="caption-text">image.png</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>The cosine similarity can be interpreted as</p>
<ul class="simple">
<li><p><strong>The projection legngth from the input vector to the subspace</strong></p></li>
<li><p><strong>The “angle” between the input vector and a subspace</strong></p></li>
</ul>
<p>or if we change our perspective the cosine similarity is inversely
related to</p>
<ul class="simple">
<li><p><strong>The rejection legngth from the input vector to the subspace</strong></p></li>
</ul>
<p>Below is an example using the subspaces calculated from the previous
data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>test_x = [1, -1]

fig, axs = plt.subplots(ncols=2)

for c, subspace in dct.items():
    m = subspace[0][0] / subspace[0][1]
    xs = np.linspace(-3,3)
    ys = m * xs

    # cos_sim = cos(θ)
    # = (eigen_vec, test_x)/|eigen_vec||test_x|
    cos_sim = np.linalg.norm(dct[c] @ test_x)
    theta = np.arccos(cos_sim)
    dist = np.sin(theta) * np.linalg.norm(test_x)
    print(f&#39;Class {c}: cosine similarity={cos_sim:.3f}, angle={np.rad2deg(theta):.3f}, rejection length={dist:.3f}&#39;)


    axs[c].quiver(0,0,*test_x, color=&#39;green&#39;, label=&#39;test_x&#39;, scale_units=&#39;xy&#39;,angles=&#39;xy&#39;,scale=1)
    axs[c].plot(xs, ys, color=cm_bright(c), label=c)
    axs[c].set_xlim(-3,3)
    axs[c].set_ylim(-3,3)
    axs[c].set_aspect(&#39;equal&#39;)
    axs[c].legend()

y_pred = 0 if np.linalg.norm(dct[0] @ test_x) &gt; np.linalg.norm(dct[1] @ test_x) else 1
print(f&#39;test_x will be classified to {y_pred}&#39;)
plt.show()
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Class</span> <span class="mi">0</span><span class="p">:</span> <span class="n">cosine</span> <span class="n">similarity</span><span class="o">=</span><span class="mf">0.731</span><span class="p">,</span> <span class="n">angle</span><span class="o">=</span><span class="mf">43.016</span><span class="p">,</span> <span class="n">rejection</span> <span class="n">length</span><span class="o">=</span><span class="mf">0.965</span>
<span class="n">Class</span> <span class="mi">1</span><span class="p">:</span> <span class="n">cosine</span> <span class="n">similarity</span><span class="o">=</span><span class="mf">1.414</span><span class="p">,</span> <span class="n">angle</span><span class="o">=</span><span class="n">nan</span><span class="p">,</span> <span class="n">rejection</span> <span class="n">length</span><span class="o">=</span><span class="n">nan</span>
<span class="n">test_x</span> <span class="n">will</span> <span class="n">be</span> <span class="n">classified</span> <span class="n">to</span> <span class="mi">1</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_8_1.png" src="../_images/output_8_1.png" />
</div>
<p>Now that we understand the subspace method, lets classify the data we
used to generate the subspaces to see how well our classifier works.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>score = 0

for i in range(len(X)):
    x = X[i]
    y_gt = y[i] # ground truth label

    # calculate projection distance to the
    # first classes subspace
    proj1 = np.linalg.norm(dct[0] @ x)

    # calculate projection distance to the
    # second classes subspace
    proj2 = np.linalg.norm(dct[1] @ x)

    assert proj1 != proj2, &#39;Tie!&#39;
    y_pred = 0 if proj1 &gt; proj2 else 1

    score += 1 if y_pred == y_gt else 0

print(score / len(y))
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.62</span>
</pre></div>
</div>
<p>The results do not look good.</p>
<p>Why could this be?</p>
<p>Let’s have a look at the decision boundary to understand what is going
on.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># This can be resused to visualize boundaries of other classifiers</span>
<span class="k">def</span> <span class="nf">plot_decision_boundaries</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

    <span class="c1"># Build mesh</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="o">.</span><span class="mi">5</span>
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="o">.</span><span class="mi">5</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span>
                         <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>

    <span class="c1"># Plot the decision boundary. For that, we will assign a color to each</span>
    <span class="c1"># point in the mesh [x_min, x_max]x[y_min, y_max].</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])[:,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Put the result into a color plot</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">8</span><span class="p">)</span>

    <span class="n">cm_bright</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">,</span> <span class="s1">&#39;#0000FF&#39;</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Score={clf.score(X,y)}&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>

<span class="c1"># Using the API provided in this package, we can easily create a subspace classifier.</span>
<span class="k">def</span> <span class="nf">format_input</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="n">t</span><span class="p">)]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">smc</span> <span class="o">=</span> <span class="n">SubspaceMethod</span><span class="p">(</span><span class="n">n_subdims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">faster_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">smc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">*</span><span class="n">format_input</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="n">smc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_decision_boundaries</span><span class="p">(</span><span class="n">smc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">*</span><span class="n">smc</span><span class="o">.</span><span class="n">dic</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">angles</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">scale_units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#FF0000&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">*</span><span class="n">smc</span><span class="o">.</span><span class="n">dic</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">angles</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">scale_units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#0000FF&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_12_0.png" src="../_images/output_12_0.png" />
</div>
<p>As you can see, the subspace method is not very good with discriminating
classes in a low dimensional space.</p>
<p>This is because the subspace method is “dimensionally hungry”, it works
much better in high dimensional data.</p>
<p>Many classification problems assume that the data given can be
represented in a much lower dimension, the subspace method is a typical
example.</p>
<p>Another point to make is that the subspace method works especially well
on class that have a fundamentally different structure. On the otherhand
it does not work when the structure of the distributions are similar.</p>
<p>In the next sections, I will give a bad use case for SM and a good use
case.</p>
</div>
<div class="section" id="bad-use-case-for-sm">
<h2>4. Bad use case for SM<a class="headerlink" href="#bad-use-case-for-sm" title="Permalink to this headline">¶</a></h2>
<p>Here I will give a bad use case for SM. In essence they both have the
same anti-pattern, that is, the generated subspaces are equal.
Classification with subspaces becomes very difficult when the subspaces
generated from pca are too similar.</p>
<p>An easy example on the 2 dimensional plane is when classes have data a
distribution with the same covariance matrix.</p>
<p>Consider the following data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">500</span><span class="p">),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">500</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">y_</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_15_0.png" src="../_images/output_15_0.png" />
</div>
<p>If we conduct pca onto these distribution we should get a very similar
eigenvectors.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_</span><span class="p">):</span>
    <span class="n">eig_vals</span><span class="p">,</span> <span class="n">eig_vecs</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">X_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_</span><span class="o">==</span><span class="n">c</span><span class="p">)],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Eigen vectors from class {c:.0f}:</span><span class="se">\n</span><span class="s1">{eig_vecs}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Eigen</span> <span class="n">vectors</span> <span class="kn">from</span> <span class="nn">class</span> <span class="mi">0</span><span class="p">:</span>
<span class="p">[[</span><span class="o">-</span><span class="mf">0.99959599</span>  <span class="mf">0.02842293</span><span class="p">]]</span>

<span class="n">Eigen</span> <span class="n">vectors</span> <span class="kn">from</span> <span class="nn">class</span> <span class="mi">1</span><span class="p">:</span>
<span class="p">[[</span><span class="o">-</span><span class="mf">0.99955934</span>  <span class="mf">0.02968376</span><span class="p">]]</span>
</pre></div>
</div>
<p>Obviously the resulting classifier is not very good.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">smc</span> <span class="o">=</span> <span class="n">SubspaceMethod</span><span class="p">(</span><span class="n">n_subdims</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">faster_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">smc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">*</span><span class="n">format_input</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">))</span>
<span class="n">smc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.524</span>
</pre></div>
</div>
</div>
<div class="section" id="good-use-case-for-sm">
<h2>5. Good use case for SM<a class="headerlink" href="#good-use-case-for-sm" title="Permalink to this headline">¶</a></h2>
<p>The subspace method becomes more powerful in higher dimensions.</p>
<p>I will demonstrate this by generating toy data in high dimensions and
apply the subspace method to it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">n_subdims</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
    <span class="n">X_</span><span class="p">,</span> <span class="n">y_</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Exhaustive search for the optimal subspace dimension</span>
    <span class="n">max_score</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># store n_subdims and score</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
        <span class="n">smc</span> <span class="o">=</span> <span class="n">SubspaceMethod</span><span class="p">(</span><span class="n">n_subdims</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">faster_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">smc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">*</span><span class="n">format_input</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">))</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">smc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>
        <span class="n">max_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span> <span class="k">if</span> <span class="n">max_score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">score</span> <span class="k">else</span> <span class="n">max_score</span>

    <span class="n">n_subdims</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">max_score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">max_score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Dimensions&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">labelcolor</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_subdims</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;n_subdims&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;n_subdims&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">labelcolor</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure align-default">
<img alt="../_images/output_22_0.png" src="../_images/output_22_0.png" />
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../source/cvt.html" class="btn btn-neutral float-right" title="cvt package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="MNIST_example_with_SM.html" class="btn btn-neutral float-left" title="MNIST example with Subspace Method" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Atom Scott

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>